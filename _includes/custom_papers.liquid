<!-- _includes/custom_papers.liquid -->
<style>
:root {
  --sigmod-color: #FFDDC1;
  --vldb-color: #C1E1FF;
  --icde-color: #D1FFC1;
  --emnlp-color: #ffc1f2ff;
  --other-color: #9f9f9fff;
}

.publications li {
  position: relative;
  padding-left: 20px; /* space for bullet */
  margin-bottom: 14px; /* tighter gap */
}

.publications li::before {
  position: absolute;
  left: 0;
  top: 4px;
  font-size: 0.65em;
  color: #555;
}

/* Title: plain, no bold */
.paper-title {
  font-weight: normal;
  font-size: 1.05em;
  margin-bottom: 2px;
}

/* Authors + metadata together = same line block */
.paper-authors {
  font-style: italic;
  margin-bottom: 0; /* no gap */
  display: inline;
}

.paper-meta {
  font-size: 0.9em;
  display: inline;
  margin-left: 6px; /* tiny spacing before tags/icons */
}

.pub-tag {
  padding: 2px 6px;
  border-radius: 12px;
  font-size: 0.85em;
  color: #000;
  display: inline-block;
  margin-left: 4px;
}
</style>

<ul class="publications">

  <li>
    <div class="paper-title">
      Data-Semantics-Aware Recommendation of Diverse Pivot Tables
    </div>

    <div class="paper-line">
      <div class="paper-authors">
        <strong>Whanhee Cho</strong>, Anna Fariha
      </div>
      <span class="pub-tag" style="background-color: var(--sigmod-color)">SIGMOD 2026</span>
      <a href="https://arxiv.org/pdf/2507.06171">ðŸ“„</a>
      <a href="https://github.com/whnhch/SAGE">ðŸ’»</a>
    </div>
  </li>

  <li>
    <div class="paper-title">
      UTOPIA: Automatic Pivot Table Assistant
    </div>

    <div class="paper-line">
      <div class="paper-authors">
        <strong>Whanhee Cho</strong>, Anna Fariha
      </div>
      <span class="pub-tag" style="background-color: var(--vldb-color)">VLDB 2024</span>
      <a href="https://dl.acm.org/doi/pdf/10.14778/3685800.3685861">ðŸ“„</a>
      <a href="https://github.com/whnhch/UTOPIA-Automatic-Pivot-Table-Assistant">ðŸ’»</a>
    </div>
  </li>

  <li>
    <div class="paper-title">
      Simple Data Transformations for Mitigating the Syntactic Similarity to Improve Sentence Embeddings at Supervised Contrastive Learning
    </div>

    <div class="paper-line">
      <div class="paper-authors">
        Minji Kim, <strong>Whanhee Cho</strong>, Soohyeong Kim, Yong Suk Choi
      </div>
      <span class="pub-tag" style="background-color: var(--other-color)">VLDB 2024</span>
      <a href="https://dl.acm.org/doi/pdf/10.14778/3685800.3685861">ðŸ“„</a>
      <a href="https://github.com/whnhch/Break-the-Similarity">ðŸ’»</a>
    </div>
  </li>

  <li>
    <div class="paper-title">
      Bidirectional Masked Self-attention and N-gram Span Attention for Constituency Parsing
    </div>

    <div class="paper-line">
      <div class="paper-authors">
        Soohyeong Kim, <strong>Whanhee Cho</strong>, Minji Kim, Yong Suk Choi
      </div>
      <span class="pub-tag" style="background-color: var(--emnlp-color)">EMNLP 2023</span>
      <a href="https://aclanthology.org/2023.findings-emnlp.25.pdf">ðŸ“„</a>
    </div>
  </li>

</ul>

